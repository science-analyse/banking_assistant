"""
RAG System for Bank of Baku Card Information
Uses ChromaDB's default embedding + Gemini for LLM
Simplest version - no quota limits on embeddings
"""

import os
import json
from typing import List, Dict, Any
from dotenv import load_dotenv
import google.generativeai as genai
import chromadb

# Load environment variables
load_dotenv()


class BankCardRAG:
    """RAG system for Bank of Baku card information"""

    def __init__(self, data_file: str = "data/rag_chunks.jsonl"):
        """Initialize RAG system"""
        # Load API key for LLM only
        self.api_key = os.getenv("LLM_API_KEY")
        if not self.api_key:
            raise ValueError("LLM_API_KEY not found in .env file")

        # Configure Gemini for LLM only
        genai.configure(api_key=self.api_key)

        # Initialize ChromaDB with default embedding function (no API needed)
        print("â³ Initializing ChromaDB with default embeddings...")
        self.chroma_client = chromadb.Client()

        # Create or get collection with default embedding function
        self.collection = self.chroma_client.get_or_create_collection(
            name="bank_cards_simple",
            metadata={"description": "Bank of Baku card information"}
        )

        # Initialize Gemini LLM
        self.model = genai.GenerativeModel('gemini-2.5-flash')

        self.data_file = data_file
        print("âœ… RAG system initialized (using free local embeddings)")

    def load_and_index_data(self):
        """Load data from JSONL and index into ChromaDB"""
        print(f"\nLoading data from {self.data_file}...")

        documents = []
        metadatas = []
        ids = []

        with open(self.data_file, 'r', encoding='utf-8') as f:
            for idx, line in enumerate(f):
                chunk = json.loads(line)

                # Prepare document text
                documents.append(chunk['text'])

                # Prepare metadata
                metadatas.append({
                    'title': chunk['metadata']['title'],
                    'card_name': chunk['metadata']['card_name'],
                    'card_type': chunk['metadata']['card_type'],
                    'source_url': chunk['metadata']['source_url'],
                    'chunk_index': str(chunk['metadata']['chunk_index']),
                    'total_chunks': str(chunk['metadata']['total_chunks'])
                })

                # Create unique ID
                ids.append(f"chunk_{idx}")

        print(f"Found {len(documents)} chunks to index")
        print("Generating embeddings locally (free, no API calls)...")

        # Add all documents at once
        self.collection.add(
            documents=documents,
            metadatas=metadatas,
            ids=ids
        )

        print(f"âœ… Successfully indexed {len(documents)} chunks")
        return len(documents)

    def retrieve(self, query: str, n_results: int = 3) -> List[Dict[str, Any]]:
        """Retrieve relevant chunks for a query"""
        results = self.collection.query(
            query_texts=[query],
            n_results=n_results
        )

        # Format results
        retrieved = []
        if results['documents'] and results['documents'][0]:
            for idx, doc in enumerate(results['documents'][0]):
                retrieved.append({
                    'text': doc,
                    'metadata': results['metadatas'][0][idx],
                    'distance': results['distances'][0][idx] if 'distances' in results else None
                })

        return retrieved

    def detect_question_type(self, query: str) -> str:
        """Detect the type of question for better formatting"""
        query_lower = query.lower()

        # Comparison questions
        comparison_keywords = ['fÉ™rq', 'ferq', 'mÃ¼qayisÉ™', 'muqayise', 'É™n yaxÅŸÄ±', 'en yaxshi',
                              'É™n yaxsi', 'hansÄ± daha', 'hansi daha', 'versus', 'vÉ™ ya', 've ya']
        if any(kw in query_lower for kw in comparison_keywords):
            return 'comparison'

        # Best/worst questions
        superlative_keywords = ['É™n', 'en', 'É™n Ã§ox', 'en cox', 'É™n az', 'en az']
        if any(kw in query_lower for kw in superlative_keywords):
            return 'superlative'

        # Feature/benefit questions
        feature_keywords = ['xÃ¼susiyyÉ™t', 'xususiyyet', 'Ã¼stÃ¼nlÃ¼k', 'ustunluk', 'fayda',
                           'imkan', 'keÅŸbek', 'kesbek', 'faiz', 'limit']
        if any(kw in query_lower for kw in feature_keywords):
            return 'features'

        # Price/cost questions
        price_keywords = ['qiymÉ™t', 'qiymet', 'haqqÄ±', 'haqqi', 'pulsuzdur', 'Ã¶dÉ™niÅŸ', 'odenis']
        if any(kw in query_lower for kw in price_keywords):
            return 'pricing'

        return 'general'

    def generate_answer(self, query: str, context_chunks: List[Dict[str, Any]]) -> str:
        """Generate answer using Gemini with retrieved context and smart formatting"""

        # Detect question type
        question_type = self.detect_question_type(query)

        # Build context from retrieved chunks
        context = "\n\n---\n\n".join([
            f"Kart: {chunk['metadata']['card_name']}\n"
            f"Tip: {chunk['metadata']['card_type']}\n"
            f"MÉ™lumat: {chunk['text']}"
            for chunk in context_chunks
        ])

        # Create smart prompt based on question type
        if question_type == 'comparison':
            formatting_instruction = """
CAVAB FORMATÄ°:
- ÆgÉ™r 2 vÉ™ ya daha Ã§ox kart mÃ¼qayisÉ™ edilirsÉ™, Markdown CÆDVÆL istifadÉ™ edin
- CÉ™dvÉ™l formatÄ±:
  | XÃ¼susiyyÉ™t | Kart 1 | Kart 2 |
  |------------|--------|--------|
  | QiymÉ™t | ... | ... |
  | Limit | ... | ... |

- Æsas fÉ™rqlÉ™ri qÄ±sa bullet pointlÉ™rlÉ™ qeyd edin
- QÄ±sa vÉ™ aydÄ±n olun"""

        elif question_type == 'superlative':
            formatting_instruction = """
CAVAB FORMATÄ°:
- ÆvvÉ™lcÉ™ qÄ±sa cavab verin (hansÄ± kart É™n yaxÅŸÄ±dÄ±r)
- Sonra É™sas sÉ™bÉ™blÉ™ri bullet pointlÉ™rlÉ™ izah edin:
  * SÉ™bÉ™b 1
  * SÉ™bÉ™b 2
- DigÉ™r alternativlÉ™ri qeyd edin
- QÄ±sa vÉ™ aydÄ±n olun"""

        elif question_type == 'features':
            formatting_instruction = """
CAVAB FORMATÄ°:
- XÃ¼susiyyÉ™tlÉ™ri bullet pointlÉ™rlÉ™ sadalayÄ±n:
  * XÃ¼susiyyÉ™t 1: izah
  * XÃ¼susiyyÉ™t 2: izah
- ÆhÉ™miyyÉ™tli rÉ™qÉ™mlÉ™ri **qalÄ±n** ÅŸriftlÉ™ gÃ¶stÉ™rin
- QÄ±sa vÉ™ aydÄ±n olun"""

        elif question_type == 'pricing':
            formatting_instruction = """
CAVAB FORMATÄ°:
- QiymÉ™tlÉ™ri aydÄ±n gÃ¶stÉ™rin (É™gÉ™r varsa):
  * Ä°llik haqqÄ±: X AZN
  * KartÄ±n qiymÉ™ti: Y AZN
- Pulsuz ÅŸÉ™rtlÉ™ri qeyd edin
- RÉ™qÉ™mlÉ™ri **qalÄ±n** ÅŸriftlÉ™ gÃ¶stÉ™rin"""

        else:  # general
            formatting_instruction = """
CAVAB FORMATÄ°:
- AydÄ±n vÉ™ strukturlaÅŸdÄ±rÄ±lmÄ±ÅŸ cavab verin
- LazÄ±m gÉ™lÉ™rsÉ™ bullet pointlÉ™r istifadÉ™ edin
- ÆhÉ™miyyÉ™tli mÉ™lumatlarÄ± **qalÄ±n** ÅŸriftlÉ™ gÃ¶stÉ™rin
- QÄ±sa vÉ™ konkret olun"""

        prompt = f"""Siz Bank of Baku-nun kart mÉ™hsullarÄ± haqqÄ±nda mÉ™lumat verÉ™n kÃ¶mÉ™kÃ§i asistansÄ±nÄ±z.

AÅŸaÄŸÄ±dakÄ± kontekst mÉ™lumatlarÄ±ndan istifadÉ™ edÉ™rÉ™k istifadÉ™Ã§inin sualÄ±na dÉ™qiq vÉ™ strukturlaÅŸdÄ±rÄ±lmÄ±ÅŸ cavab verin.
CavabÄ±nÄ±z AzÉ™rbaycan dilindÉ™ olmalÄ±dÄ±r vÉ™ yalnÄ±z verilmiÅŸ kontekstdÉ™ olan mÉ™lumatlara É™saslanmalÄ±dÄ±r.

{formatting_instruction}

KONTEKST:
{context}

Ä°STÄ°FADÆÃ‡Ä° SUALI:
{query}

CAVAB (Markdown formatÄ±nda):"""

        # Generate response
        response = self.model.generate_content(prompt)
        return response.text

    def is_list_all_question(self, question: str) -> bool:
        """Detect if question is asking for a list of all cards"""
        list_keywords = [
            'hansÄ±', 'hansi', 'nÉ™', 'ne', 'neÃ§É™', 'nece',
            'var', 'mÃ¶vcud', 'movcud', 'olur', 'burax',
            'kartlar', 'kartlarÄ±', 'kartlari', 'kredit kartlar'
        ]

        question_lower = question.lower()

        # Check for multiple list indicators
        keyword_count = sum(1 for kw in list_keywords if kw in question_lower)

        # If question is short and has list keywords, it's likely a list question
        if keyword_count >= 2 and len(question.split()) <= 6:
            return True

        # Specific patterns
        list_patterns = [
            'hansÄ± kartlar', 'hansi kartlar',
            'hansÄ± kredit', 'hansi kredit',
            'nÉ™ kartlar var', 'ne kartlar var',
            'neÃ§É™ kart', 'nece kart'
        ]

        return any(pattern in question_lower for pattern in list_patterns)

    def get_all_unique_cards(self, card_type: str = None) -> List[Dict[str, Any]]:
        """Get all unique cards from the database"""
        all_data = self.collection.get()

        unique_cards = {}
        if all_data['metadatas']:
            for metadata in all_data['metadatas']:
                card_name = metadata['card_name']
                c_type = metadata['card_type']

                # Filter by card type if specified
                if card_type and c_type != card_type:
                    continue

                if card_name not in unique_cards:
                    unique_cards[card_name] = {
                        'card_name': card_name,
                        'card_type': c_type,
                        'title': metadata['title'],
                        'url': metadata['source_url']
                    }

        return list(unique_cards.values())

    def query(self, question: str, n_results: int = 3, verbose: bool = False) -> Dict[str, Any]:
        """
        Main RAG query function with intelligent handling

        Args:
            question: User's question in Azerbaijani
            n_results: Number of chunks to retrieve
            verbose: If True, return detailed information

        Returns:
            Dictionary with answer and metadata
        """
        print(f"\nğŸ” Sual: {question}")

        # Check if this is a "list all" question
        if self.is_list_all_question(question):
            print("ğŸ“‹ SiyahÄ± tipli sual aÅŸkarlandÄ± - bÃ¼tÃ¼n kartlarÄ± gÉ™tirirÉ™m...")

            # Determine if asking for credit or debet specifically
            card_type = None
            if 'kredit' in question.lower():
                card_type = 'credit'
            elif 'debet' in question.lower():
                card_type = 'debet'

            # Get all unique cards
            all_cards = self.get_all_unique_cards(card_type)
            print(f"ğŸ“š {len(all_cards)} unikal kart tapÄ±ldÄ±")

            # Create context with all cards
            context = "\n\n---\n\n".join([
                f"Kart: {card['card_name']}\n"
                f"Tip: {card['card_type']}\n"
                f"URL: {card['url']}"
                for card in all_cards
            ])

            prompt = f"""Siz Bank of Baku-nun kart mÉ™hsullarÄ± haqqÄ±nda mÉ™lumat verÉ™n kÃ¶mÉ™kÃ§i asistansÄ±nÄ±z.

AÅŸaÄŸÄ±da Bank of Baku-da mÃ¶vcud olan bÃ¼tÃ¼n kartlarÄ±n siyahÄ±sÄ± verilmiÅŸdir.
Ä°stifadÉ™Ã§iyÉ™ bu kartlarÄ± sadalayÄ±n vÉ™ hÉ™r birinin adÄ±nÄ± qeyd edin.

MÃ–VCUD KARTLAR:
{context}

Ä°STÄ°FADÆÃ‡Ä° SUALI:
{question}

CAVAB (BÃ¼tÃ¼n kartlarÄ± sadalayÄ±n):"""

            answer = self.model.generate_content(prompt).text

            return {
                'answer': answer,
                'sources': all_cards,
                'card_count': len(all_cards)
            }

        # Regular RAG query
        retrieved_chunks = self.retrieve(question, n_results)
        print(f"ğŸ“š {len(retrieved_chunks)} relevant chunk tapÄ±ldÄ±")

        if not retrieved_chunks:
            return {
                'answer': "Ãœzr istÉ™yirik, bu sual haqqÄ±nda mÉ™lumat tapa bilmÉ™dim.",
                'sources': [],
                'retrieved_chunks': []
            }

        # Generate answer
        print("ğŸ¤– Cavab hazÄ±rlanÄ±r...")
        answer = self.generate_answer(question, retrieved_chunks)

        # Prepare sources
        sources = []
        for chunk in retrieved_chunks:
            sources.append({
                'card_name': chunk['metadata']['card_name'],
                'card_type': chunk['metadata']['card_type'],
                'url': chunk['metadata']['source_url']
            })

        result = {
            'answer': answer,
            'sources': sources
        }

        if verbose:
            result['retrieved_chunks'] = retrieved_chunks

        return result


def main():
    """Example usage"""
    print("=" * 60)
    print("Bank of Baku RAG System")
    print("=" * 60)

    # Initialize RAG system
    rag = BankCardRAG(data_file="data/rag_chunks.jsonl")

    # Load and index data
    rag.load_and_index_data()

    print("\n" + "=" * 60)
    print("RAG System Ready!")
    print("=" * 60)

    # Example queries
    example_queries = [
        "Bolkart kredit kartÄ±nÄ±n ÅŸÉ™rtlÉ™ri nÉ™lÉ™rdir?",
        "MaaÅŸ kartÄ± ilÉ™ nÉ™ qÉ™dÉ™r kredit gÃ¶tÃ¼rÉ™ bilÉ™rÉ™m?",
    ]

    print("\nğŸ“ Test suallarÄ±:\n")
    for idx, query in enumerate(example_queries, 1):
        print(f"\n{idx}. {query}")
        result = rag.query(query, n_results=2)
        print(f"\nğŸ’¬ Cavab:\n{result['answer']}\n")
        print(f"ğŸ“ MÉ™nbÉ™lÉ™r: {[s['card_name'] for s in result['sources']]}\n")
        print("-" * 60)


if __name__ == "__main__":
    main()
