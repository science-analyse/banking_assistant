# Quick Start Guide - Bank of Baku RAG Data

## ğŸ¯ What You Have Now

**20 RAG-ready chunks** in multiple formats, enhanced from original scraped data.

```
Original Data â†’ Normalization â†’ RAG-Ready Data
   20 pages         â†“              20 chunks
   (6 good)     Enhanced         (all usable)
   (14 minimal)  + Context
```

## ğŸ“Š Data Breakdown

### High Quality (6 chunks) â­
- News articles about bonds, campaigns, services
- Average 200 words per chunk
- Quality score: 0.95
- **Perfect for RAG**

### Enhanced Medium Quality (14 chunks)
- Product pages with added context
- Average 66 words per chunk
- Quality score: 0.60
- **Usable with fallbacks**

## ğŸš€ 3-Step Quick Start

### Step 1: Generate Embeddings (5 minutes)

```bash
pip install sentence-transformers

python3 << 'PYTHON'
import json
from sentence_transformers import SentenceTransformer

# Load data
with open('embeddings_ready.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

# Generate embeddings
model = SentenceTransformer('intfloat/multilingual-e5-large')
texts = [item['text'] for item in data]
embeddings = model.encode(texts)

print(f"âœ“ Generated {len(embeddings)} embeddings")
# Save embeddings
import numpy as np
np.save('embeddings.npy', embeddings)
PYTHON
```

### Step 2: Set Up Vector DB (5 minutes)

```bash
pip install chromadb

python3 << 'PYTHON'
import json
import numpy as np
import chromadb

# Load
with open('embeddings_ready.json', 'r') as f:
    data = json.load(f)
embeddings = np.load('embeddings.npy')

# Setup ChromaDB
client = chromadb.Client()
collection = client.create_collection("bank_of_baku")

# Add documents
for i, item in enumerate(data):
    collection.add(
        ids=[item['id']],
        embeddings=[embeddings[i].tolist()],
        documents=[item['text']],
        metadatas=[item['metadata']]
    )

print("âœ“ Vector database ready!")
PYTHON
```

### Step 3: Test Retrieval (2 minutes)

```python
# Query example
results = collection.query(
    query_texts=["MaaÅŸ kartÄ± haqqÄ±nda mÉ™lumat"],
    n_results=3
)

for i, doc in enumerate(results['documents'][0]):
    print(f"\n{i+1}. {doc[:200]}...")
```

## ğŸ“ File Guide

| File | Size | Use For |
|------|------|---------|
| `embeddings_ready.json` | 19KB | **START HERE** - Generate embeddings |
| `normalized_chunks.json` | 75KB | Full metadata, analysis |
| `normalized_chunks.jsonl` | 69KB | Streaming, batch processing |
| `category_index.json` | 674B | Category filtering |
| `normalization_stats.json` | 367B | Data statistics |

## âš¡ One-Command Demo

```bash
# Install dependencies + generate embeddings + setup DB
pip install sentence-transformers chromadb && python3 -c "
import json
from sentence_transformers import SentenceTransformer
import chromadb

# Load
with open('embeddings_ready.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

# Generate embeddings
model = SentenceTransformer('intfloat/multilingual-e5-large')
embeddings = model.encode([item['text'] for item in data])

# Setup DB
client = chromadb.Client()
collection = client.create_collection('bank_of_baku')

# Add data
for i, item in enumerate(data):
    collection.add(
        ids=[item['id']],
        embeddings=[embeddings[i].tolist()],
        documents=[item['text']],
        metadatas=[item['metadata']]
    )

# Test query
results = collection.query(
    query_texts=['MaaÅŸ kartÄ± haqqÄ±nda'],
    n_results=2
)

print('\nâœ“ RAG System Ready!')
print('\nTest Results:')
for doc in results['documents'][0]:
    print(f'- {doc[:100]}...')
"
```

## ğŸ¯ Expected Performance

| Query Type | Coverage | Action |
|------------|----------|--------|
| News/campaigns | âœ… 95% | Direct answer |
| Product basics | âœ… 70% | Answer + contact |
| Detailed questions | âš ï¸ 30% | Fallback to 145 |

## ğŸ“š Next Steps

1. âœ… Read: `README.md` (detailed documentation)
2. âœ… Review: `RAG_IMPLEMENTATION_GUIDE.md` (complete guide)
3. âœ… Check: `RAG_SUITABILITY_ANALYSIS.md` (data quality analysis)

## ğŸ†˜ Common Issues

**Q: Embeddings too slow?**
A: Use smaller model: `paraphrase-multilingual-MiniLM-L12-v2`

**Q: Need better quality?**
A: See `RAG_SUITABILITY_ANALYSIS.md` for enhancement options

**Q: How to handle low-quality responses?**
A: Use hybrid system (see `RAG_IMPLEMENTATION_GUIDE.md`)

---

**Ready to build your RAG system!** ğŸš€
